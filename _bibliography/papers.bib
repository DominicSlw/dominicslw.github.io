@misc{sun2024edcopilot,
      title={ED-Copilot: Reduce Emergency Department Wait Time with Language Model Diagnostic Assistance}, 
      author={Liwen Sun and Abhineet Agarwal and Aaron Kornblith and Bin Yu and Chenyan Xiong},
      year={2024},
      arxiv={2402.13448},
      abbr={ICML 2024},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      abstract={In the emergency department (ED), patients undergo triage and multiple laboratory tests before diagnosis. This process is time-consuming, and causes ED crowding which significantly impacts patient mortality, medical errors, staff burnout, etc. This work proposes (time) cost-effective diagnostic assistance that explores the potential of artificial intelligence (AI) systems in assisting ED clinicians to make time-efficient and accurate diagnoses. Using publicly available patient data, we collaborate with ED clinicians to curate MIMIC-ED-Assist, a benchmark that measures the ability of AI systems in suggesting laboratory tests that minimize ED wait times, while correctly predicting critical outcomes such as death. We develop ED-Copilot which sequentially suggests patient-specific laboratory tests and makes diagnostic predictions. ED-Copilot uses a pre-trained bio-medical language model to encode patient information and reinforcement learning to minimize ED wait time and maximize prediction accuracy of critical outcomes. On MIMIC-ED-Assist, ED-Copilot improves prediction accuracy over baselines while halving average wait time from four hours to two hours. Ablation studies demonstrate the importance of model scale and use of a bio-medical language model. Further analyses reveal the necessity of personalized laboratory test suggestions for diagnosing patients with severe cases, as well as the potential of ED-Copilot in providing ED clinicians with informative laboratory test recommendations.}
}

@misc{sun2024factawaremultimodalretrievalaugmentation,
      title={Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation}, 
      author={Liwen Sun and James Zhao and Megan Han and Chenyan Xiong},
      year={2024},
      arxiv={2407.15268},
      abbr={NAACL 2025<br>GenAI4Health<br>@ NeurIPS 2024},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.15268}, 
      abstract={Multimodal foundation models hold significant potential for automating radiology report generation, thereby assisting clinicians in diagnosing cardiac diseases. However, generated reports often suffer from serious factual inaccuracy. In this paper, we introduce a fact-aware multimodal retrieval-augmented pipeline in generating accurate radiology reports (FactMM-RAG). We first leverage RadGraph to mine factual report pairs, then integrate factual knowledge to train a universal multimodal retriever. Given a radiology image, our retriever can identify high-quality reference reports to augment multimodal foundation models, thus enhancing the factual completeness and correctness of report generation. Experiments on two benchmark datasets show that our multimodal retriever outperforms state-of-the-art retrievers on both language generation and radiology-specific metrics, up to 6.5% and 2% score in F1CheXbert and F1RadGraph. Further analysis indicates that employing our factually-informed training strategy imposes an effective supervision signal, without relying on explicit diagnostic label guidance, and successfully propagates fact-aware capabilities from the multimodal retriever to the multimodal foundation model in radiology report generation.}

}

@misc{CitePredSun,
      title={Citation Prediction for Text-rich Network}, 
      author={Sun, Liwen and Hu, Wei and He, Xinyi and Zhu, Qi and Han, Jiawei},
      year={2022},
      pdf={https://drive.google.com/file/d/16NlWuGnYAH3HgoH7jMKbwIRUWMsHDU0Y/view?usp=sharing},
      abbr={ArXiv},
      abstract={Recommending high-quality citations for research papers is challenging. Graph information can be beneficial to predict what papers one should cite for a research paper, given the paper title, abstract, contents, venue to submit, and authors. However, existing approaches heavily depend on text information via pre-trained language models (PLMs) from the content and neglect the impact of famous papers and authors. The main disadvantage of text-based approaches is the vulnerability to distribution shift when a new trend appears. Also, simply utilizing text signals from language models cannot characterize graph structures due to their sequence architecture. Thus we would be discussing and exploring the idea of joint modeling graph and text to facilitate mutual enhancement in text-rich networks for citation prediction based on multiple types of relationships and entities.}
}

@misc{sun2022fewshot,
      title={Few-shot Text Classification with Dual Contrastive Consistency}, 
      author={Liwen Sun and Jiawei Han},
      year={2022},
      arxiv={2209.15069},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      abbr={ArXiv},
      abstract={In this paper, we explore how to utilize pre-trained language model to perform few-shot text classification where only a few annotated examples are given for each class. Since using traditional cross-entropy loss to fine-tune language model under this scenario causes serious overfitting and leads to sub-optimal generalization of model, we adopt supervised contrastive learning on few labeled data and consistency-regularization on vast unlabeled data. Moreover, we propose a novel contrastive consistency to further boost model performance and refine sentence representation. After conducting extensive experiments on four datasets, we demonstrate that our model (FTCC) can outperform state-of-the-art methods and has better robustness.}
}

@misc{Casual,
      title={Causal Fusion for Recommender System}, 
      author={Sun, Liwen and Zhang, Chi and Su, Zilin and Zhang, Feiran and Zhou, Yuen},
      year={2022},
      pdf={https://iopscience.iop.org/article/10.1088/1742-6596/2547/1/012018},
      abbr={CONF-CDS},
      abstract={Recommender system suffers from huge selection bias from users, which makes utilizing causal inference to solve this problem becomes a necessary problem. However, traditional rating model only utilizing biased dataset and unbiased estimator cannot remarkably be improved. Thus, we fused the unbiased dataset into training model and combine it with jointly learning method to better improve the original baselines. Extensive experiments verify that the proposed doubly robust joint leaning method after fusing unbiased, missing rating data can significantly outperform the state-of-the-art methods and can dramatically reduce the error from rating model with the increasing number of unbiased data..}
}